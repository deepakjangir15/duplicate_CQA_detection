{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1WZT38IEU84H4wEKGBp_7iUf2NTNgPoRF",
      "authorship_tag": "ABX9TyNBcNZXQaRljvHzcR9i0KAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakjangir15/duplicate_CQA_detection/blob/main/Tensorflow_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u03t8gOlTCZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('/content/drive/MyDrive/unzipped/checkpoint6.pkl')"
      ],
      "metadata": {
        "id": "iBDPY-vWmKHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 50000\n",
        "max_length = 20\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length = max_length)"
      ],
      "metadata": {
        "id": "tQCj3Cs4mVeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1_train = data[\"question1\"]\n",
        "q2_train = data[\"question2\"]"
      ],
      "metadata": {
        "id": "mBM1KLaXm2a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_q1,val_q1,train_q2, val_q2, train_labels, val_labels = train_test_split(q1_train.to_numpy(),\n",
        "                                                                              q2_train.to_numpy(),\n",
        "                                                                            data[\"is_duplicate\"].to_numpy(),\n",
        "                                                                            test_size=0.15, # dedicate 15% of samples to validation set\n",
        "                                                                            random_state=101) # random state for reproducibility\\"
      ],
      "metadata": {
        "id": "5CeWLdEImqpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_q1.shape,val_q1.shape,train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQPkGDfJnBGY",
        "outputId": "af376984-f237-47a4-9e3d-21b877869830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((338747,), (59779,), (338747,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the questions into a tf.data dataset\n",
        "\n",
        "train_questions_data = tf.data.Dataset.from_tensor_slices((train_q1,train_q2))\n",
        "train_labels_data = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "train_questions_dataset = tf.data.Dataset.zip((train_questions_data, train_labels_data))\n",
        "\n",
        "train_questions_dataset = train_questions_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_questions_data = tf.data.Dataset.from_tensor_slices((val_q1,val_q2))\n",
        "val_labels_data = tf.data.Dataset.from_tensor_slices(val_labels)\n",
        "val_questions_dataset = tf.data.Dataset.zip((val_questions_data, val_labels_data))\n",
        "\n",
        "val_questions_dataset = val_questions_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "vj7x0z3ynO7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_questions_data:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCkHqNO1nJ4N",
        "outputId": "702a9235-b240-4e13-c0e4-c21101fe61de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'Facebook fbml add fan button to page facebook facebook-fbml try figure button acebook page right next company name see do page show following screenshot enter image description add application though find great deal information code require actual button place button page anyone point right direction thanks'>, <tf.Tensor: shape=(), dtype=string, numpy=b'How to develop ajax web applications in Scala? ajax oop scala lift web-frameworks look object orient framework develop application cala ideally would like something like without mix client code cala server code short example cala could create vertical layout label list code label abel nothing select list item1 item2 election value label text value page ontent ertical ayout label '>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average number of tokens present in the training data - Question 1\n",
        "\n",
        "round(sum([len(i.split()) for i in train_q1])/len(train_q1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwtvjTODnh0y",
        "outputId": "5fe1f920-cadb-4f0f-96fd-d859c49d4c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average number of tokens present in the training data - Question 2\n",
        "\n",
        "round(sum([len(i.split()) for i in train_q2])/len(train_q2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQFjbc7MnwpG",
        "outputId": "f4255221-fad3-4d7f-bb16-f68e6d49228e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 50000\n",
        "max_length = 20\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length = max_length)\n",
        "\n",
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_questions_data)"
      ],
      "metadata": {
        "id": "w-kjicCQn3dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"Where are the seven wonders of the world?\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrgofiZMn_W0",
        "outputId": "0a2c5d9b-f1d3-4d2a-9181-5ed7b4d25536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
              "array([[  153,    14,     3,  5669, 38799,    12,     3,   238,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(train_q1)\n",
        "print(f'Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized text:')\n",
        "text_vectorizer(random_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVTUqLZCobyv",
        "outputId": "87c35bb1-2203-4f98-fda6-ce5d90f495d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "In iOS, how should I be obtaining the screen's height and width, including width being greater than height in landscape mode? iphone ios objective-c ipad background-image function render background code height creen main creen bound size height width creen main creen bound size width code height width retina device landscape mode height 1024 width image display rotation portrait image turn device side image neatly fill whole screen asis background display horizontall      \n",
            "\n",
            "Vectorized text:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
              "array([    9,   356,     8,    64,    10,    55, 12003,     3, 13096,\n",
              "         307,    13,   310,  3025,   310,   437,  4900,   273,   307,\n",
              "           9,  3077])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the unique words present in the vocabulary\n",
        "vocab_words = text_vectorizer.get_vocabulary()\n",
        "top_5_words = vocab_words[:5]\n",
        "bottom_5_words = vocab_words[-5:]\n",
        "\n",
        "print(f\"Number of words in vocab: {len(vocab_words)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrxH77Ckok-T",
        "outputId": "d29fbaec-c662-468f-fb90-90a5a6a7003b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 50000\n",
            "Top 5 most common words: ['', '[UNK]', 'code', 'the', 'what']\n",
            "Bottom 5 least common words: ['skd', 'skates', 'sk', 'sizers', 'sixdigit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length,\n",
        "                             name='embedding1')\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn5tX8-gopJB",
        "outputId": "9f5f3e2f-9faa-44f7-c615-3c7df47b214d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f3d8c557700>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(train_q1)\n",
        "print(f'Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded text:')\n",
        "\n",
        "sample_embedded_text = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embedded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cvr1SjFpqmK",
        "outputId": "7221d871-5291-45ea-aa68-7a280d622800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "how do i translate this english sentence into german      \n",
            "\n",
            "Embedded text:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 20, 128), dtype=float32, numpy=\n",
              "array([[[ 0.01545889, -0.03671843,  0.01988218, ...,  0.03288582,\n",
              "         -0.02877569, -0.00503626],\n",
              "        [ 0.0130278 ,  0.02627177,  0.04028996, ...,  0.03127203,\n",
              "          0.03451768, -0.03823571],\n",
              "        [-0.01714529, -0.0376454 ,  0.01133369, ..., -0.03178798,\n",
              "          0.04614197, -0.03610648],\n",
              "        ...,\n",
              "        [ 0.00931767,  0.03379751,  0.03879407, ..., -0.04418159,\n",
              "          0.04225722, -0.01176969],\n",
              "        [ 0.00931767,  0.03379751,  0.03879407, ..., -0.04418159,\n",
              "          0.04225722, -0.01176969],\n",
              "        [ 0.00931767,  0.03379751,  0.03879407, ..., -0.04418159,\n",
              "          0.04225722, -0.01176969]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 - Simple Dense Model"
      ],
      "metadata": {
        "id": "GLQXgK1qpwn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = text_vectorizer(token_inputs_q1)\n",
        "x = embedding(token_embeddings_q1)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = text_vectorizer(token_inputs_q2)\n",
        "x = embedding(token_embeddings_q2)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,outputs=token_output_q2)"
      ],
      "metadata": {
        "id": "forK-gzjp2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_1_token')\n"
      ],
      "metadata": {
        "id": "HzwsiHnIqLZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_1_history = model_1.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5DdcKtFq5Qi",
        "outputId": "734f2775-8925-4193-e5ae-3ff474a121dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 358s 34ms/step - loss: 0.5157 - accuracy: 0.7423 - val_loss: 0.4655 - val_accuracy: 0.7742\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 348s 33ms/step - loss: 0.4308 - accuracy: 0.7972 - val_loss: 0.4413 - val_accuracy: 0.7911\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 352s 33ms/step - loss: 0.3797 - accuracy: 0.8271 - val_loss: 0.4450 - val_accuracy: 0.7938\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 350s 33ms/step - loss: 0.3420 - accuracy: 0.8470 - val_loss: 0.4658 - val_accuracy: 0.7915\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 348s 33ms/step - loss: 0.3122 - accuracy: 0.8623 - val_loss: 0.4796 - val_accuracy: 0.7971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights = model_1.get_layer('embedding1').get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZaJpThfrMmh",
        "outputId": "f401cbd3-2075-4749-bded-756039a2af11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "fLoREP2J19yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting _TensorSliceDataset to numpy array\n",
        "\n",
        "labels = tf.compat.v1.data.make_one_shot_iterator(val_labels_data.batch(len(val_labels_data))).get_next()"
      ],
      "metadata": {
        "id": "GMG5YRzn1mFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs = model_1.predict(val_questions_dataset)\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "\n",
        "model_1_results = calculate_results(y_true=labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSOukkr_rOeO",
        "outputId": "f1e0bb9f-11e0-4e82-b6c8-5eae255f79e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1869/1869 [==============================] - 3s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.71026614697469,\n",
              " 'precision': 0.7987207787386681,\n",
              " 'recall': 0.797102661469747,\n",
              " 'f1': 0.7968363529771887}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 - LSTM"
      ],
      "metadata": {
        "id": "ZuyIybc33U6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embedding_2')\n",
        "\n",
        "\n",
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = text_vectorizer(token_inputs_q1)\n",
        "x = model_2_embedding(token_embeddings_q1)\n",
        "x = layers.LSTM(64)(x)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = text_vectorizer(token_inputs_q2)\n",
        "x = model_2_embedding(token_embeddings_q2)\n",
        "x = layers.LSTM(64)(x)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,outputs=token_output_q2)\n",
        "\n",
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_2_token')\n",
        "\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_2_history = model_2.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3Qy8No3qQL",
        "outputId": "a8988eed-6f56-436c-e75c-fcff5146a993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 394s 37ms/step - loss: 0.5236 - accuracy: 0.7397 - val_loss: 0.4756 - val_accuracy: 0.7658\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 391s 37ms/step - loss: 0.4325 - accuracy: 0.7957 - val_loss: 0.4744 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 391s 37ms/step - loss: 0.3568 - accuracy: 0.8375 - val_loss: 0.5400 - val_accuracy: 0.7685\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 391s 37ms/step - loss: 0.2924 - accuracy: 0.8710 - val_loss: 0.6241 - val_accuracy: 0.7588\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 391s 37ms/step - loss: 0.2458 - accuracy: 0.8943 - val_loss: 0.7403 - val_accuracy: 0.7592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzyauQrA4j7c",
        "outputId": "708758c7-b067-4730-86c0-0c3ffb927241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_token\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " token_input_q1 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " token_input_q2 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text_vectorization_2 (TextVect  (None, 20)          0           ['token_input_q1[0][0]',         \n",
            " orization)                                                       'token_input_q2[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 20, 128)      6400000     ['text_vectorization_2[4][0]',   \n",
            "                                                                  'text_vectorization_2[5][0]']   \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 64)           49408       ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           49408       ['embedding_2[1][0]']            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          8320        ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128)          8320        ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " token_questions_cat (Concatena  (None, 256)         0           ['dense_6[0][0]',                \n",
            " te)                                                              'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 256)          0           ['token_questions_cat[0][0]']    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 64)           16448       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64)           0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            65          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,531,969\n",
            "Trainable params: 6,531,969\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3 - GRU"
      ],
      "metadata": {
        "id": "E8FnNqJc46ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embedding_3')\n",
        "\n",
        "\n",
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = text_vectorizer(token_inputs_q1)\n",
        "x = model_3_embedding(token_embeddings_q1)\n",
        "x = layers.GRU(64)(x)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = text_vectorizer(token_inputs_q2)\n",
        "x = model_3_embedding(token_embeddings_q2)\n",
        "x = layers.GRU(64)(x)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,outputs=token_output_q2)\n",
        "\n",
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_3_token')\n",
        "\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_3_history = model_3.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_fcrvyL5EXr",
        "outputId": "7274e4c7-f91e-4b7b-b3e1-3dbde83a296a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 402s 38ms/step - loss: 0.5223 - accuracy: 0.7393 - val_loss: 0.4715 - val_accuracy: 0.7659\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 400s 38ms/step - loss: 0.4305 - accuracy: 0.7970 - val_loss: 0.4784 - val_accuracy: 0.7736\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 400s 38ms/step - loss: 0.3638 - accuracy: 0.8340 - val_loss: 0.5216 - val_accuracy: 0.7715\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 372s 35ms/step - loss: 0.3055 - accuracy: 0.8640 - val_loss: 0.5921 - val_accuracy: 0.7681\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 377s 36ms/step - loss: 0.2605 - accuracy: 0.8865 - val_loss: 0.6860 - val_accuracy: 0.7646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "4X3x6z7a5XUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4 - Bidirectional LSTM"
      ],
      "metadata": {
        "id": "AbGD3hJU5aXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embedding_4')\n",
        "\n",
        "\n",
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = text_vectorizer(token_inputs_q1)\n",
        "x = model_4_embedding(token_embeddings_q1)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = text_vectorizer(token_inputs_q2)\n",
        "x = model_4_embedding(token_embeddings_q2)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,outputs=token_output_q2)\n",
        "\n",
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_4_token')\n",
        "\n",
        "model_4.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_4_history = model_4.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dMlc0W85eR4",
        "outputId": "9267e02e-ba17-4f15-a78a-575ad461b9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 389s 36ms/step - loss: 0.5148 - accuracy: 0.7435 - val_loss: 0.4642 - val_accuracy: 0.7708\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 378s 36ms/step - loss: 0.4148 - accuracy: 0.8078 - val_loss: 0.4619 - val_accuracy: 0.7814\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 382s 36ms/step - loss: 0.3339 - accuracy: 0.8522 - val_loss: 0.5161 - val_accuracy: 0.7745\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 389s 37ms/step - loss: 0.2668 - accuracy: 0.8858 - val_loss: 0.6033 - val_accuracy: 0.7678\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 385s 36ms/step - loss: 0.2181 - accuracy: 0.9084 - val_loss: 0.7822 - val_accuracy: 0.7705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfJB87y_5oln",
        "outputId": "8ff277cb-37f7-4af7-fdee-a0dd21a4763c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_token\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " token_input_q1 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " token_input_q2 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text_vectorization_2 (TextVect  (None, 20)          0           ['token_input_q1[0][0]',         \n",
            " orization)                                                       'token_input_q2[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 20, 128)      6400000     ['text_vectorization_2[8][0]',   \n",
            "                                                                  'text_vectorization_2[9][0]']   \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 128)          98816       ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 128)         98816       ['embedding_4[1][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          16512       ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 128)          16512       ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " token_questions_cat (Concatena  (None, 256)         0           ['dense_14[0][0]',               \n",
            " te)                                                              'dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 256)          0           ['token_questions_cat[0][0]']    \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 64)           16448       ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 64)           0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 1)            65          ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,647,169\n",
            "Trainable params: 6,647,169\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5 - Conv1D"
      ],
      "metadata": {
        "id": "H4yKjjIj5rXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embedding_5')\n",
        "\n",
        "\n",
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = text_vectorizer(token_inputs_q1)\n",
        "x = model_5_embedding(token_embeddings_q1)\n",
        "x = layers.Conv1D(filters=32,kernel_size=5,activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = text_vectorizer(token_inputs_q2)\n",
        "x = model_5_embedding(token_embeddings_q2)\n",
        "x = layers.Conv1D(filters=32,kernel_size=5,activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(x)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,outputs=token_output_q2)\n",
        "\n",
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_5_token')\n",
        "\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_5_history = model_5.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYQt9xC-5uGJ",
        "outputId": "e0eff858-543e-4a4f-dedc-eff3d4e70400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 362s 34ms/step - loss: 0.5175 - accuracy: 0.7417 - val_loss: 0.4702 - val_accuracy: 0.7696\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 361s 34ms/step - loss: 0.4137 - accuracy: 0.8077 - val_loss: 0.4599 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 374s 35ms/step - loss: 0.3189 - accuracy: 0.8596 - val_loss: 0.5194 - val_accuracy: 0.7736\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 371s 35ms/step - loss: 0.2405 - accuracy: 0.8982 - val_loss: 0.6077 - val_accuracy: 0.7708\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 358s 34ms/step - loss: 0.1882 - accuracy: 0.9229 - val_loss: 0.7634 - val_accuracy: 0.7694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv5FqjlD6OoV",
        "outputId": "6b9cfc90-83e4-4c62-dc37-bc11ef663644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_token\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " token_input_q1 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " token_input_q2 (InputLayer)    [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text_vectorization_2 (TextVect  (None, 20)          0           ['token_input_q1[0][0]',         \n",
            " orization)                                                       'token_input_q2[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 20, 128)      6400000     ['text_vectorization_2[13][0]',  \n",
            "                                                                  'text_vectorization_2[14][0]']  \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 16, 32)       20512       ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 16, 32)       20512       ['embedding_5[1][0]']            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 32)          0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 32)          0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 128)          4224        ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 128)          4224        ['global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " token_questions_cat (Concatena  (None, 256)         0           ['dense_23[0][0]',               \n",
            " te)                                                              'dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 256)          0           ['token_questions_cat[0][0]']    \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 64)           16448       ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 64)           0           ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 1)            65          ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,465,985\n",
            "Trainable params: 6,465,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Model 6 - TF hub Sentence Encoder"
      ],
      "metadata": {
        "id": "l_MZyRC56VjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "question_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name='USE')"
      ],
      "metadata": {
        "id": "nBqwKclT6XqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_inputs_q1 = layers.Input(shape=[], dtype=tf.string, name='token_input_q1')\n",
        "token_embeddings_q1 = question_encoder_layer(token_inputs_q1)\n",
        "token_output_q1 = layers.Dense(128, activation='relu')(token_embeddings_q1)\n",
        "token_model_q1 = tf.keras.Model(inputs=token_inputs_q1,\n",
        "                             outputs=token_output_q1)\n",
        "\n",
        "token_inputs_q2 = layers.Input(shape=[], dtype=tf.string, name='token_input_q2')\n",
        "token_embeddings_q2 = question_encoder_layer(token_inputs_q2)\n",
        "token_output_q2 = layers.Dense(128, activation='relu')(token_embeddings_q2)\n",
        "token_model_q2 = tf.keras.Model(inputs=token_inputs_q2,\n",
        "                             outputs=token_output_q2)\n",
        "\n",
        "token_questions_concat = layers.Concatenate(name='token_questions_cat')([token_model_q1.output,\n",
        "                                                                         token_model_q2.output])\n",
        "\n",
        "combined_dropout = layers.Dropout(0.5)(token_questions_concat)\n",
        "combined_dense = layers.Dense(64, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(final_dropout)\n",
        "\n",
        "model_6 = tf.keras.Model(inputs=[token_model_q1.input,token_model_q2.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_6_token')\n",
        "\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6_history = model_6.fit(train_questions_dataset,\n",
        "                              epochs=5,\n",
        "                              validation_data=val_questions_dataset,\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzMqNYb96pj9",
        "outputId": "ca12fb40-0c0a-4a9f-f9d5-f3c83dc4795f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10586/10586 [==============================] - 98s 9ms/step - loss: 0.5487 - accuracy: 0.7154 - val_loss: 0.4822 - val_accuracy: 0.7644\n",
            "Epoch 2/5\n",
            "10586/10586 [==============================] - 93s 9ms/step - loss: 0.4966 - accuracy: 0.7531 - val_loss: 0.4533 - val_accuracy: 0.7788\n",
            "Epoch 3/5\n",
            "10586/10586 [==============================] - 93s 9ms/step - loss: 0.4774 - accuracy: 0.7662 - val_loss: 0.4420 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "10586/10586 [==============================] - 94s 9ms/step - loss: 0.4658 - accuracy: 0.7739 - val_loss: 0.4308 - val_accuracy: 0.7940\n",
            "Epoch 5/5\n",
            "10586/10586 [==============================] - 93s 9ms/step - loss: 0.4569 - accuracy: 0.7788 - val_loss: 0.4277 - val_accuracy: 0.7951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "id": "iC87kOYt6xT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_6)"
      ],
      "metadata": {
        "id": "n14fDL4e6ykR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the most wrongly predicted questions"
      ],
      "metadata": {
        "id": "1O_FS_vz65XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.DataFrame({'questions': val_questions,\n",
        "                       'Is Duplicate?': val_labels,\n",
        "                       'predicted': model_7_preds,\n",
        "                       'pred_prob': tf.squeeze(model_7_pred_probs)})\n",
        "\n",
        "val_df.head()"
      ],
      "metadata": {
        "id": "BR-gf7Ah69kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wron_predictions = val_df[val_df['Is Duplicate?'] != val_df['predicted']].sort_values('pred_prob', ascending=False)\n",
        "wron_predictions.head(10)"
      ],
      "metadata": {
        "id": "sk2WOI657EtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in wron_predictions.head(10)[['questions','Is Duplicate?','predicted','pred_prob']].itertuples():\n",
        "  _,question,target,pred,pred_prob = row\n",
        "  print(f'{question} \\nTarget: {target}\\nPred: {pred} Pred Prob: {pred_prob}')"
      ],
      "metadata": {
        "id": "Sns7COUY7GRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "From the overall analysis. It is seen that out of 10 most incorrect predictions made by our models, it is observed that 8 are out of the stack overflow dataset."
      ],
      "metadata": {
        "id": "QVxpjPUe7H9j"
      }
    }
  ]
}